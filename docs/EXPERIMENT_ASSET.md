# ğŸ–¼ï¸ Asset-Based Experiments (XTIM)

Asset-based experiments are designed to present **image stimuli from disk** in controlled sequences. Ideal for cognitive and affective research requiring naturalistic or structured visual input.

---

## ğŸ“‚ Script Location

The asset experiment scripts are located in:

```
experiments/
â”œâ”€â”€ core-asset-stim.py    â† for Pupil Core setups
â”œâ”€â”€ neo-asset-stim.py     â† for Pupil Neo setups
```

---

## ğŸ§  Purpose

These scripts display pre-rendered images in `.tiff` or `.png` format from the `script-images/` directory, supporting:

- Timed sequences
- Inter-stimulus intervals
- Display logging
- Synchronized triggers

---

## ğŸš€ Running an Asset Experiment

```bash
xtim run core-asset --exp proyect_name
xtim run neo-asset --exp proyect_name
```

Or manually:

```bash
python experiments/core-asset-stim.py
# or
python experiments/neo-asset-stim.py
```

---

## âš™ï¸ Configuration File

File: `config/experiment.toml`

```toml
[experiment]
type = "asset"
hardware = "core"  # or "neo"
stimulus_duration = 1.0
inter_stimulus_interval = 0.5
```

---

## ğŸ“‚ Stimuli Folder

Images must be placed in:

```
my_experiment/script-images/
â”œâ”€â”€ welcome.tiff
â”œâ”€â”€ goodbye.tiff
â”œâ”€â”€ stimulus_001.tiff
â””â”€â”€ ...
```

Make sure filenames are valid and ordered correctly if sequencing matters.

---

## ğŸ§ª Specific Features

- Loads high-resolution `.tiff` images
- Sends event markers to eye-tracking device
- Logs timestamps per stimulus
- Handles resolution and screen fitting automatically

---

## ğŸ”¬ Use Cases

- Image recognition
- Memory encoding/recall
- Visual categorization
- Affective image processing

---
